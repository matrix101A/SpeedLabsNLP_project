# -*- coding: utf-8 -*-
"""calssification_project_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CsGOwVRswLqo1T_ePLfZAtGK0rV5OzkB

## Importing Libraries
"""

import pandas as pd 
import numpy as np 
import json 
import IPython

from binascii import a2b_base64
import urllib

from IPython.display import Image

from IPython.core.debugger import Pdb; 
!pip install pymssql
import pymssql

"""## Importing CSV data and latex data and merginge them, then perform pre processing to remove duplicate question"""

bio_data = pd.read_csv('data-bio.csv')
bio_data

# checking how much data have image information present 
image_data = bio_data[pd.isnull(bio_data.imageHTML) == False]
print('questions with image are ',image_data.shape[0])
image_data.to_csv('questions_with_image.csv')

image_data[['QuestionId','imageHTML','Q_Latex']].to_csv('questions_with_image.csv')

"""### Taking all questions with non nan  imageHTML and checking if latex files are corretly converted to images 

"""

# problems in running in colab 
for index, row in image_data.iterrows():
    image_html = row['imageHTML'];
    image_html=image_html.split('src= "')
    image_url = image_html[1].split('" >')
    data = image_url[0]
    response = urllib.request.urlopen(data)
    with open('image.jpg', 'wb') as f:
        f.write(response.file.read())
    question_latex = row['Q_Latex'];
    print(question_latex)
    img = Image(filename='image.jpg') 
    display(img)    
    Pdb().set_trace()
    # type continue in text box to go to next image, quit() to exit the loop

"""### Codes for pre processing and splitting data """

def example_trial_split(data):

  example_data = data[data.UseAs == 'Example']
  print('number of example data are', example_data.shape[0])
  trial_data = data[data.UseAs == 'Trial']
  print('number of trial data are', trial_data.shape[0])

  trial_data.to_csv('trial_data_bio.csv')
  example_data.to_csv('example_data_bio.csv')

  return trial_data, example_data

# extracting Q_latex column 


# Defining functions for preprocessing step to remove latex specific characters and punctuations

# removes a list of words (ie. stopwords) from a tokenized list.
def removeWords(listOfTokens, listOfWords):
    return [token for token in listOfTokens if token not in listOfWords]


# removes any words composed of less than 2 or more than 21 letters
def twoLetters(listOfTokens):
    twoLetterWord = []
    for token in listOfTokens:
        if len(token) <= 2 or len(token) >= 21:
            twoLetterWord.append(token)
    return twoLetterWord

latex_keywords=['begin','end','mathrm','Idots''idots','quad','a','b','c','d','i','ii','iii','iv','vii','longrightarrow',       
                'hline','rightarrow','column','text','array','begin','end','III','nm','none','one','frac'];

                
question_types=['true','false','assertion','asassertion','reason','correct','explanation','incorrect','questions','option','options'
               'statement','carefully','followed','following','incorrect','statements',
                 'assertion',
                 'statement',
                 'contains',
                 'select',
                 'reason',
                 'two',
                 'options',
                 'question',
                 'describes',
                 'answer',
                 'best',
                 'basis',
                 'correctexplanation',
                 'readthem',
                 'you',
                 'responses',
                 'answering',
                 'consist','(',')','_']

# main pre processing step 
nltk.download('stopwords')
nltk.download('punkt')
stopwords = nltk.corpus.stopwords.words('english')  # defining stopwords from english language 
param_stemmer = SnowballStemmer('english')#defining stemmer to convert words to their root form 

## This code removes the punctuation, latex keywords and garbage values, can be customized according to need 
def preProcess(Question_text):
    for question in Question_text:
            index = Question_text.index(question)
            Question_text[index] = Question_text[index].replace(',', '')         # Removes commas
            Question_text[index] = Question_text[index].replace('\\', '')        # Removes \
            Question_text[index] = Question_text[index].replace('\n', '')        # removed newline
            Question_text[index] = Question_text[index].replace('-', '')        # removed newline
            Question_text[index] = Question_text[index].replace('~', '')        # Removes \
            Question_text[index] = Question_text[index].replace('=', '')        # Removes \



            Question_text[index] = Question_text[index].casefold()               # Makes all letters lowercase
            Question_text[index] = re.sub('\W_',' ', Question_text[index])       # removes specials characters 
            Question_text[index] = re.sub("\d"," ", Question_text[index])       # removes numbers
            listOfTokens = word_tokenize(Question_text[index])
            twoLetterWord = twoLetters(listOfTokens)
            

            listOfTokens = removeWords(listOfTokens, latex_keywords)    #remove all the latex keywords from our data
            listOfTokens = removeWords(listOfTokens, question_types)     #words such as assertion,reason,true,false etc
            listOfTokens = removeWords(listOfTokens, stopwords)
            listOfTokens = removeWords(listOfTokens, twoLetterWord)
            


            Question_text[index]   = " ".join(listOfTokens)
            Question_text[index] = unidecode(Question_text[index])
      
    return Question_text

def get_top_features_cluster(tf_idf_array, prediction, n_feats):
    labels = np.unique(prediction)
    dfs = []
    for label in labels:
        id_temp = np.where(prediction==label) # indices for each cluster
        x_means = np.mean(tf_idf_array[id_temp], axis = 0) # returns average score across cluster
        sorted_means = np.argsort(x_means)[::-1][:n_feats] # indices with top 20 scores
        features = vectorizer.get_feature_names()
        best_features = [(features[i], x_means[i]) for i in sorted_means]
        df = pd.DataFrame(best_features, columns = ['features', 'score'])
        dfs.append(df)
    return dfs

def plotWords(dfs, n_feats):
    plt.figure(figsize=(8, 4))
    for i in range(0, len(dfs)):
        plt.title(("Most Common Words in Cluster {}".format(i)), fontsize=10, fontweight='bold')
        sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[i][:n_feats])
        plt.show()

def get_top_features_cluster_ind(tf_idf_array, prediction, n_feats,lab):
    labels = np.unique(prediction)
    dfs = []
    label = lab;
    id_temp = np.where(prediction==label) # indices for each cluster
    x_means = np.mean(tf_idf_array[id_temp], axis = 0) # returns average score across cluster
    sorted_means = np.argsort(x_means)[::-1][:n_feats] # indices with top 20 scores
    features = vectorizer.get_feature_names()
    best_features = [(features[i], x_means[i]) for i in sorted_means]
    df = pd.DataFrame(best_features, columns = ['features', 'score'])
    return df

def preProcessDeepLearning(example_data , trial_data , label):
  example_data['split']= 'train'
  test_data = trial_data
  test_data['split'] = 'test'
  merged_test_train_data = example_data.append(test_data)
  merged_test_train_data =merged_test_train_data[['Q_Latex',label,'split']] # select the column you want as label
  merged_test_train_data.rename(columns = {'Q_Latex':'sentence',	label:'label'}, inplace = True)
  return merged_test_train_data;

# Define a function to compute the max length of sequence
def max_length(sequences):
    max_length = 0
    for i, seq in enumerate(sequences):
        length = len(seq)
        if max_length < length:
            max_length = length
    return max_length

def make_pred(model,test_x,corpus):
  tokenizer = Tokenizer(oov_token=oov_tok)
  tokenizer.fit_on_texts(train_x)
  training_sequences = tokenizer.texts_to_sequences(train_x)
  test_sequences = tokenizer.texts_to_sequences(test_x)
  max_len = max_length(training_sequences)


  Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)
  Xtrain = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)


  predictions= model.predict(Xtest,verbose= 0 )
  first_predictions= np.argmax(predictions,axis= 1).tolist()
  test_corpus = corpus[corpus['split'] == 'test']
  correct_code = test_corpus['label'].tolist()
  correct_labels = [chapter_mapping[chapter_mapping['label_code']== pred_label]['label'].tolist()[0]
                            for pred_label in correct_code ]
  first_predicted_labels = [chapter_mapping[chapter_mapping['label_code']== pred_label]['label'].tolist()[0]
                            for pred_label in first_predictions ]
  test_corpus['First_prediction'] = first_predicted_labels
  test_corpus['CorrectLabel'] = correct_labels
  test_corpus[test_corpus['First_prediction'] == test_corpus['CorrectLabel']]
  return test_corpus;

def create_tokenizer(sentences):
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(sentences)
    return tokenizer

def train_test_split(corpus):
  # Separate the sentences and the labels
  # Separate the sentences and the labels for training and testing

  train_x = list(corpus[corpus.split=='train'].sentence)
  train_y = np.array(corpus[corpus.split=='train'].label)

  test_x = list(corpus[corpus.split=='test'].sentence)
  test_y = np.array(corpus[corpus.split=='test'].label)
  print('length of test data is - ', len(test_x))
  print('length of train data is - ', len(train_x))
  return train_x,train_y, test_x,test_y

def accuracyTopThreeKSCText():

    pred_seq_wise = []
    for i in range(0,len(Xtest)-1):
      ques_text = test_x[i:i +1]
      test_ques = tokenizer_total.texts_to_matrix(ques_text, mode='freq')

      subject_pred= model_subjcet_total.predict(test_ques)
      subject_pred= np.argmax(subject_pred,axis= 1).tolist()
      subject_pred=subject_pred[0]
      pred_subject_label = subject_mapping[subject_mapping['label_code'] == subject_pred].label.tolist()[0]
      if(pred_subject_label != trial_data.SubjectName.tolist()[i]):
        pred_seq_wise.append(0) ;

      else :
        if(pred_subject_label == 'Biology'):
          test_ques = tokenizer_bio.texts_to_matrix(ques_text, mode='freq')
          chapter_pred= model_chapter_bio.predict(test_ques)
          ksc_model = model_KSC_bio
          pred_prob = chapter_mapping_bio
          ksc_mapping = KSC_mapping_bio
          pred_prob['Probability']=chapter_pred[0]
          valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
          pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]

        elif(pred_subject_label == 'Chemistry'): 
          test_ques = tokenizer_chm.texts_to_matrix(ques_text, mode='freq')
          chapter_pred= model_chapter_chm.predict(test_ques)
          ksc_model = model_KSC_chm
          pred_prob = chapter_mapping_chm
          ksc_mapping = KSC_mapping_chm
          pred_prob['Probability']=chapter_pred[0]
          valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
          pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]

        elif(pred_subject_label == 'Physics'):
          test_ques = tokenizer_phy.texts_to_matrix(ques_text, mode='freq')
          chapter_pred= model_chapter_phy.predict(test_ques)
          pred_prob = chapter_mapping_phy
          ksc_model = model_KSC_phy
          ksc_mapping = KSC_mapping_phy
          pred_prob['Probability']=chapter_pred[0]
          valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
          pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]

        elif(pred_subject_label == 'Maths'):
          test_ques = tokenizer_math.texts_to_matrix(ques_text, mode='freq')
          chapter_pred= model_chapter_math.predict(test_ques)
          pred_prob = chapter_mapping_math
          ksc_model = model_KSC_math
          ksc_mapping = KSC_mapping_math
          pred_prob['Probability']=chapter_pred[0]
          valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
          pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]

        if(pred_chapter_label != trial_data.ChapterName.tolist()[i]):
            pred_seq_wise.append(0) ;

        else: 
          KSC_pred = ksc_model.predict(test_ques)
          pred_prob = ksc_mapping
          pred_prob['Probability']=KSC_pred[0]
          valid_KSC = trial_data[trial_data['ChapterName']==pred_chapter_label ].KSCText.unique()
          try:
            correct_KSC = trial_data.KSCText.tolist()[i]
            correct_KSC_ind=total_KSC_list.index(correct_KSC)
            pred_KSC_label_first = pred_prob[pred_prob['label'].isin(valid_KSC)].sort_values('Probability',ascending=False).label.tolist()[0]
          
            pred_KSC_label_second = pred_prob[pred_prob['label'].isin(valid_KSC)].sort_values('Probability',ascending=False).label.tolist()[1]
            pred_KSC_label_third = pred_prob[pred_prob['label'].isin(valid_KSC)].sort_values('Probability',ascending=False).label.tolist()[2]
      
            
            if(pred_KSC_label_first == correct_KSC or pred_KSC_label_second == correct_KSC or pred_KSC_label_third == correct_KSC):
              result = 1;
              pred_seq_wise.append(1) ;
              
                
            else :
              result = 0 ;
              pred_seq_wise.append(0) ;
            
          except :
            try:
              if(pred_KSC_label_first == correct_KSC or pred_KSC_label_second == correct_KSC):
                result = 1;
                pred_seq_wise.append(1) ;
              else :
                result = 0 ;
                pred_seq_wise.append(0) ;
                
            except :
                if(pred_KSC_label_first == correct_KSC):
                  result = 1;
                  pred_seq_wise.append(1) ;
                else :
                  result = 0 ;
                  pred_seq_wise.append(0) ;


          try: 
            if(pred_KSC_label_first != correct_KSC and pred_KSC_label_second == correct_KSC):  # If this happens then the first label 
                  first_ksc_index =  total_KSC_list.index(pred_KSC_label_first)                 # can be in a cluster with second 
                  KSC_sim_array[first_ksc_index,correct_KSC_ind] =  KSC_sim_array[first_ksc_index,correct_KSC_ind] + 1
                  KSC_sim_array[correct_KSC_ind,first_ksc_index] =  KSC_sim_array[correct_KSC_ind,first_ksc_index] + 1
          except:
            continue
    return pred_seq_wise

def accuracyTopThreeKSCClsuter(test_with_cluster):
  pred_seq_wise = []

  for i in range(0, len(Xtest)-1):
    ques_text = test_x[i:i +1]
    test_ques = tokenizer_total.texts_to_matrix(ques_text, mode='freq')

    subject_pred= model_subjcet_total.predict(test_ques)
    subject_pred= np.argmax(subject_pred,axis= 1).tolist()
    subject_pred=subject_pred[0]
    pred_subject_label = subject_mapping[subject_mapping['label_code'] == subject_pred].label.tolist()[0]
    if(pred_subject_label != trial_data.SubjectName.tolist()[i]):
      pred_seq_wise.append(0) ;

    else :
      if(pred_subject_label == 'Biology'):
        test_ques = tokenizer_bio.texts_to_matrix(ques_text, mode='freq')
        chapter_pred= model_chapter_bio.predict(test_ques)
        ksc_model = model_KSC_bio
        pred_prob = chapter_mapping_bio
        ksc_mapping = KSC_mapping_bio
        pred_prob['Probability']=chapter_pred[0]
        valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
        pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]

      elif(pred_subject_label == 'Chemistry'): 
        test_ques = tokenizer_chm.texts_to_matrix(ques_text, mode='freq')
        chapter_pred= model_chapter_chm.predict(test_ques)
        ksc_model = model_KSC_chm
        pred_prob = chapter_mapping_chm
        ksc_mapping = KSC_mapping_chm
        pred_prob['Probability']=chapter_pred[0]
        valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
        pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]

      elif(pred_subject_label == 'Physics'):
        test_ques = tokenizer_phy.texts_to_matrix(ques_text, mode='freq')
        chapter_pred= model_chapter_phy.predict(test_ques)
        pred_prob = chapter_mapping_phy
        ksc_model = model_KSC_phy
        ksc_mapping = KSC_mapping_phy
        pred_prob['Probability']=chapter_pred[0]
        valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
        pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]

      elif(pred_subject_label == 'Maths'):
        test_ques = tokenizer_math.texts_to_matrix(ques_text, mode='freq')
        chapter_pred= model_chapter_math.predict(test_ques)
        pred_prob = chapter_mapping_math
        ksc_model = model_KSC_math
        ksc_mapping = KSC_mapping_math
        pred_prob['Probability']=chapter_pred[0]
        valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
        pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]

      if(pred_chapter_label != trial_data.ChapterName.tolist()[i]):
          pred_seq_wise.append(0) ;

      else: 
        KSC_pred = ksc_model.predict(test_ques)
        pred_prob = ksc_mapping
        pred_prob['Probability']=KSC_pred[0]
        valid_KSC = trial_data[trial_data['ChapterName']==pred_chapter_label ].KSCText.unique()
        try:
          correct_KSC = trial_data.KSCText.tolist()[i]
          correct_KSC_cluster = test_with_cluster[test_with_cluster['KSCText']== correct_KSC].KSCClusterName.tolist()[0];


          pred_KSC_label_first = pred_prob[pred_prob['label'].isin(valid_KSC)].sort_values('Probability',ascending=False).label.tolist()[0];
          pred_KSC_cluster_first=test_with_cluster[test_with_cluster['KSCText']==pred_KSC_label_first].KSCClusterName.tolist()[0];

          pred_KSC_label_second=[]
          pred_KSC_cluster_second=[]
          pred_KSC_label_second = pred_prob[pred_prob['label'].isin(valid_KSC)].sort_values('Probability',ascending=False).label.tolist()[1];
          pred_KSC_cluster_second=test_with_cluster[test_with_cluster['KSCText']==pred_KSC_label_second].KSCClusterName.tolist()[0];

          pred_KSC_label_third=[]
          pred_KSC_cluster_third=[]
          pred_KSC_label_third = pred_prob[pred_prob['label'].isin(valid_KSC)].sort_values('Probability',ascending=False).label.tolist()[2];
          pred_KSC_cluster_third=test_with_cluster[test_with_cluster['KSCText']==pred_KSC_label_third].KSCClusterName.tolist()[0];

    
          
          if(pred_KSC_cluster_first == correct_KSC_cluster or pred_KSC_cluster_second == correct_KSC_cluster or pred_KSC_cluster_third == correct_KSC_cluster):
            result = 1;
            pred_seq_wise.append(1) ;
          else :
            result = 0 ;
            pred_seq_wise.append(0) ;
        except :
          try:
            if(pred_KSC_cluster_first == correct_KSC_cluster or pred_KSC_cluster_second == correct_KSC_cluster):
              result = 1;
              pred_seq_wise.append(1) ;
            else :
              result = 0 ;
              pred_seq_wise.append(0) ;
              
          except :
              if(pred_KSC_cluster_first == correct_KSC_cluster):
                result = 1;
                pred_seq_wise.append(1) ;
              else :
                result = 0 ;
                pred_seq_wise.append(0) ;
  return pred_seq_wise

"""## Models"""

def simple_NN_model(no_label = 10, max_len = 100 ):
    model = tf.keras.models.Sequential([
        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(max_len,)),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense( units=no_label, activation='softmax')
    ])
    
  
    return model

"""## Creating test and train data for cluster analysis """

data_bio = pd.read_csv('data-bio.csv').reset_index()
trial_data_bio, example_data_bio = example_trial_split(data_bio)

# exploring the example_data 
print('Number of topics covered by example data',(example_data_bio['TopicName'].unique()).shape[0])
print('Number of Chapters covered by example data',(example_data_bio['ChapterName'].unique()).shape[0])
print('Number of KSC covered by example data',(example_data_bio['KSCText'].unique()).shape[0])
print('Questions lacking latex data ', sum(pd.isnull(example_data_bio['Q_Latex'])) )

"""## Analysing data by topic, chapter and KSC text 


### Maximum questions are of Human Physiology followed by Genetics and Evolution
"""

### print('Columns in example data are ',example_data.columns)
grouped_by_chapter = example_data_bio.groupby('ChapterName').count()
grouped_by_chapter=grouped_by_chapter.sort_values(by = 'index',ascending=False)
grouped_by_chapter=grouped_by_chapter[grouped_by_chapter['index']>20]
grouped_by_chapter

"""### We take only chapters which have > 20 questions avaialbe. Number of such chapters are 15"""

abundant_chapters= grouped_by_chapter.index.tolist()
example_data_filtered_bio= example_data_bio[example_data_bio['ChapterName'].isin(abundant_chapters)]
trial_data_filtered_bio= trial_data_bio[trial_data_bio['ChapterName'].isin(abundant_chapters)]
example_data_filtered_bio.to_csv('example_data_filtered_bio.csv')
trial_data_filtered_bio.to_csv('trial_data_filtered_bio.csv')
print('Length of filtered example data is ',len(example_data_filtered_bio))
print('Length of filtered trial data is ',len(trial_data_filtered_bio))

"""### Questions belonging to Bacteria: Role in Agriculture and Industry KSC cluster has maximum number of questions """

grouped_ksc_text = example_data_bio.groupby('KSCText').count()
grouped_ksc_text.sort_values(by = 'index',ascending=False)
kcs_abundant = grouped_ksc_text[grouped_ksc_text['index']> 5].index #  Prints KSC text which occur 
print('KSC which have more than 5 questions- ',len(kcs_abundant))                    #> 5 times in our dataet

"""## K-means cluster anslysis """

#Choose which dataset to use as training 
example_data = example_data_filtered_bio; 
trial_data = trial_data_filtered_bio;


num_clusters = example_data['ChapterName'].unique().shape[0];  # deine num of clusters to be formed with data, this can be set as number of chapters or KSC as desired 
no_example_data = len(example_data);
no_trial_data = len(trial_data);

merged_test_train_data = example_data.append(trial_data)
merged_test_train_data

"""## importing libraries for K means

"""

# Corpus Processing
! pip install unidecode
import re
import nltk.corpus
from unidecode                        import unidecode
from nltk.tokenize                    import word_tokenize
from nltk                             import SnowballStemmer
from sklearn.feature_extraction.text  import TfidfVectorizer
from sklearn.preprocessing            import normalize

# K-Means
from sklearn import cluster

# Visualization and Analysis
import matplotlib.pyplot  as plt
import matplotlib.cm      as cm
import seaborn            as sns
from sklearn.metrics      import silhouette_samples, silhouette_score
from wordcloud            import WordCloud

# Map Viz
import folium
#import branca.colormap as cm
from branca.element import Figure

merged_test_train_data

# main pre processing step 
Question_text = merged_test_train_data['Q_Latex'].tolist()
Question_text= preProcess(Question_text)
print('Text after pre processing', Question_text)

"""## Performing K means

### Following is the example of the types of question belonging to the same KSC, we can see some similarity in keywords so we can hope to get thses grouped during cluster analysis
"""

example_data[example_data['KSCText'] == 'types of eggs - based on distribution of yolk'].Q_Latex.tolist()

"""### Here we apply TF-IDF vectorization in our data which gives us the most important words present in our document 


### Referecne - https://towardsdatascience.com/text-vectorization-term-frequency-inverse-document-frequency-tfidf-5a3f9604da6d
"""

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(Question_text)   # fitting our questions document to vectorizer 
tf_idf = pd.DataFrame(data = X.toarray(), columns=vectorizer.get_feature_names())

vectorized_question_data  = tf_idf

#print("{} rows".format(final_df.shape[0]))
vectorized_question_data.T.nlargest(5, 0)   # getting top 5 words with most importance

"""### We have converted the questions data into a vectorized form where each word has features which is its relative importance in each question. We will use this data in our K means algorithm.


### Here we run our K means algorithm - https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html
"""

## Running K means aglorithm 

k = num_clusters  # defining the number of clusters which we want, for now it is the number of chapters we have ie 27

kmeans = cluster.KMeans(n_clusters = k
                               , init = 'k-means++'    # automatically selects clusters 
                               , n_init = 10           # number of times to run K means
                               , random_state = 1
                               , algorithm = 'full')

vectorized_example_data = vectorized_question_data[0:no_example_data];
vectorized_trial_data = vectorized_question_data[no_example_data:];
kmeans_result = kmeans.fit(vectorized_example_data)    # pass data in form n_samples * n_features

predicted_cluster_labels = kmeans_result.predict(vectorized_question_data)
n_feats = 20
dfs = get_top_features_cluster(vectorized_question_data.to_numpy(), predicted_cluster_labels, n_feats)
plotWords(dfs, 13)

"""### Snippet to get top features of particular cluster"""

get_top_features_cluster_ind(vectorized_question_data.to_numpy(), predicted_cluster_labels, n_feats,3).features.tolist()

"""### We now assign labels to our original data and see how it classifies, We can see that most clusters have dominantly 1 chapter present. We label the cluster based on chapter occuring with max frequency """

labels = kmeans.labels_ 
example_data['label'] = labels
example_data.head()

cluster_label = []
for i in range(0,num_clusters):
    cluster_questions = example_data[example_data['label'] == i ]  #get all questions belonging to cluster i 
    cluster_chapters_list = cluster_questions['ChapterName'].tolist();
    plt.figure(figsize=(16,4))
    plt.hist(cluster_chapters_list)
    plt.xticks(rotation=45)
    cluster_label.append(max(set(cluster_chapters_list), key = cluster_chapters_list.count));
    plt.title(("Most Common Chapters in Cluster {}".format(i)), fontsize=10, fontweight='bold')

"""### We check how many questions are classified to each cluster 


"""

for i in range(0,num_clusters):
    print('No of Questions belonging to cluster ', i ,'are ',sum(example_data['label'] == i))

cluster_label[11] # cluster 11 has a very large number of questions in it. 
                #This is beacause Principles of Inheritance and Variation has highest contribution in example data

"""### We now check how many chapter can we cover by using the above method. It is seen that we can only cover 9 chapters out ot 27"""

classified_chapters_clusters = np.unique(np.array(cluster_label)).tolist();
print(classified_chapters_clusters, len(classified_chapters_clusters))

example_data.ChapterName.unique().tolist()

"""### Our algorithm classifies data into 15 clusters which major represent 8 out of 15 chapters taken in example data. We see how was the propotion of this chapters in our example data """

classfied_chapters_df= example_data[example_data['ChapterName'].isin(classified_chapters_clusters)]
classfied_chapters_df = classfied_chapters_df.groupby('ChapterName').count()
classfied_chapters_df

"""### We can see that only those chapters which have >60 questions in examples data have only been able to be classified by our algorithm 

### We now look at the propotion of chapters which could not be represented in our classification
"""

unclassfied_chapters_df= example_data[[not elem for elem in 
                                           example_data['ChapterName'].isin(classified_chapters_clusters).tolist()]]
unclassfied_chapters_df=  unclassfied_chapters_df.groupby('ChapterName').count()
unclassfied_chapters_df

"""### We can see that topics not classified by this algorithm has <60 questions, this means that we need more questions from these topics to classify them correctly

### Testing the accuracy of this classification on test data 

### We will only use test data from the 8 chapters that we are able to classify correctly and see how accurate our classification is in assigning topics to these questions
"""

trial_data
vectorized_trial_data= vectorized_trial_data[trial_data['ChapterName'].isin(classified_chapters_clusters).tolist()];
trial_data_filtered = trial_data[trial_data['ChapterName'].isin(classified_chapters_clusters)]
vectorized_trial_data

predicted_cluster_labels = kmeans_result.predict(vectorized_trial_data)

"""### We see what chapter the clustering algorithm predicts for us using the test data """

trial_data_filtered_prediction = trial_data_filtered
trial_data_filtered_prediction['label']=predicted_cluster_labels
trial_data_filtered_prediction['predicted_chapter']=[cluster_label[label] for label in 
                                                     trial_data_filtered_prediction['label'].tolist()]

trial_data_filtered_prediction

correct_predictions = trial_data_filtered_prediction[trial_data_filtered_prediction[
    'ChapterName']==trial_data_filtered_prediction['predicted_chapter']]

test_acctracy = correct_predictions.shape[0]/trial_data_filtered_prediction.shape[0]
print('Accuracy for classfing test data is', test_acctracy* 100)

"""### Most of the incorrect predictions are into the chapter Principles of Inheritance and Variation. This may be because it forms a huge chunk of our example data"""

incorrect_predictions = trial_data_filtered_prediction[trial_data_filtered_prediction
                                            ['ChapterName']!=trial_data_filtered_prediction['predicted_chapter']]
print('Number of incorrect predictions',incorrect_predictions.shape[0]);
print('Incorrect Predictions to Principles of Inheritance and Variation-',
      sum(incorrect_predictions['predicted_chapter']=='Principles of Inheritance and Variation'))

"""###  Notes - 
###  There is a need to standardize example data from all topic, currently one topic test data dominates the other

### We can strenthen the 20 limit for min number of questions from a topic

## Using Deep learning techniques

#### Import libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
import random
from nltk.corpus import stopwords, twitter_samples
# from nltk.tokenize import TweetTokenizer
from sklearn.model_selection import KFold
from nltk.stem import PorterStemmer
from string import punctuation
from sklearn.preprocessing import OneHotEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
import time

# %config IPCompleter.greedy=True
# %config IPCompleter.use_jedi=False
# nltk.download('twitter_samples')

"""### doing preprocessing"""

merged_test_train_data= preProcessDeepLearning(example_data,trial_data,'ChapterName') 
# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 

uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
chapter_mapping= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)

corpus ## This is final data to be used

"""Preparing dataset for model



"""



train_x,train_y, test_x, test_y = train_test_split(corpus)

# do some custom pre processing
train_x= preProcess(train_x)
test_x  = preProcess(test_x)
train_x[4]

"""### Tokenizing data and padding """

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

trunc_type='post'
padding_type='post'
oov_tok = "<UNK>"

# Cleaning and Tokenization
tokenizer = Tokenizer(oov_token=oov_tok)
tokenizer.fit_on_texts(train_x)

print("Example of sentence: ", train_x[4])

# Turn the text into sequence
training_sequences = tokenizer.texts_to_sequences(train_x)
max_len = max_length(training_sequences)

print('Into a sequence of int:', training_sequences[4])

# Pad the sequence to have the same size
training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)
print('Into a padded sequence:', training_padded[4])

# See the first 10 words in the vocabulary

word_index = tokenizer.word_index
for i, word in enumerate(word_index):
    print(word, word_index.get(word))
    if i==9:
        break
vocab_size = len(word_index)+1
print(vocab_size)

"""### Defining model  and callbacks"""

from tensorflow.keras import regularizers
from tensorflow.keras.constraints import MaxNorm

def define_model_cnn(filters = 100, kernel_size = 3, activation='relu', input_dim = None, output_dim=300, len_max = None, no_labels= 3 ):
    
    model = tf.keras.models.Sequential([
        tf.keras.layers.Embedding(input_dim=vocab_size, 
                                  output_dim=output_dim, 
                                  input_length=len_max, 
                                  input_shape=(len_max, )),
        
        tf.keras.layers.Conv1D(filters=filters, kernel_size = kernel_size, activation = activation, 
                               # set 'axis' value to the first and second axis of conv1D weights (rows, cols)
                               kernel_constraint= MaxNorm( max_value=3, axis=[0,1])),
        
        tf.keras.layers.MaxPool1D(2),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(10, activation=activation, 
                              # set axis to 0 to constrain each weight vector of length (input_dim,) in dense layer
                              kernel_constraint = MaxNorm( max_value=3, axis=0)),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(units=no_labels, activation='softmax')
    ])
    
    model.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
#     model.summary()
    return model

model_0 = define_model_cnn( input_dim=1000, len_max=100, no_labels=10 )
model_0.summary()

class myCallback(tf.keras.callbacks.Callback):
    # Overide the method on_epoch_end() for our benefit
    def on_epoch_end(self, epoch, logs={}):
        if (logs.get('accuracy') > 0.93):
            print("\nReached 93% accuracy so cancelling training!")
            self.model.stop_training=True


callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, 
                                             patience=20, verbose=2, 
                                             mode='auto', restore_best_weights=True)
# callbacks = myCallback()

"""### Testing different kernel sizes"""

# Parameter Initialization
trunc_type='post'
padding_type='post'
oov_tok = "<UNK>"
activations = ['relu', 'tanh']
filters = 100
kernel_sizes = [1, 2, 3, 4, 5, 6]

columns = ['Activation', 'Filters', 'Acc']
record = pd.DataFrame(columns = columns)


for activation in activations:

    for kernel_size in kernel_sizes:

        # encode data using
        # Cleaning and Tokenization
        tokenizer = Tokenizer(oov_token=oov_tok)
        tokenizer.fit_on_texts(train_x)

        # Turn the text into sequence
        training_sequences = tokenizer.texts_to_sequences(train_x)
        test_sequences = tokenizer.texts_to_sequences(test_x)

        max_len = max_length(training_sequences)

        # Pad the sequence to have the same size
        Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)
        Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)

        word_index = tokenizer.word_index
        vocab_size = len(word_index)+1

        # Define the input shape
        model = define_model_cnn(filters, kernel_size, activation, input_dim=vocab_size, len_max=max_len, no_labels = no_labels)
         # Train the model
        model.fit(Xtrain, train_y, batch_size=50, epochs=60, verbose=2, callbacks=[callbacks], validation_data=(Xtest, test_y))

        # evaluate the model
        loss, acc = model.evaluate(Xtest, test_y, verbose=0)
        print('Test Accuracy: {}'.format(acc*100))

        parameters = [activation, kernel_size]
        entries = parameters + [acc]

        temp = pd.DataFrame([entries], columns=columns)
        record = record.append(temp, ignore_index=True)
        print()
        print(record)
        print()

record.sort_values(by='Acc', ascending=False)

"""### Run model on bio data """

# Parameter Initialization

def run_cnn_model(no_labels, activation, kernel_size,train_x,test_x,train_test =''):
      trunc_type='post'
      padding_type='post'
      oov_tok = "<UNK>"
      filters = 100
 

      columns = ['Activation', 'Filters', 'Acc']
      record = pd.DataFrame(columns = columns)


      # encode data using
      # Cleaning and Tokenization
      tokenizer = Tokenizer(oov_token=oov_tok)
      tokenizer.fit_on_texts(train_x)

      # Turn the text into sequence
      training_sequences = tokenizer.texts_to_sequences(train_x)
      test_sequences = tokenizer.texts_to_sequences(test_x)

      max_len = max_length(training_sequences)

      # Pad the sequence to have the same size
      Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)
      Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)

      word_index = tokenizer.word_index
      vocab_size = len(word_index)+1

      # Define the input shape
      model = define_model_cnn(filters, kernel_size, activation, input_dim=vocab_size, len_max=max_len,no_labels = no_labels)
        # Train the model
      model.fit(Xtrain, train_y, batch_size=50, epochs=60, verbose=2, callbacks=[callbacks], validation_data=(Xtest, test_y))

      # evaluate the model
      loss, acc = model.evaluate(Xtest, test_y, verbose=0)
      print('Test Accuracy: {}'.format(acc*100))

      parameters = [activation, kernel_size]
      entries = parameters + [acc]

      temp = pd.DataFrame([entries], columns=columns)
      record = record.append(temp, ignore_index=True)
      print()
      print(record)
      print()
      return  model

model_bio=  run_cnn_model(no_labels= no_labels, activation= 'tanh', kernel_size = 1,train_x=train_x ,test_x= test_x)

"""### make pred"""

predicted_df = make_pred(model_bio,test_x= test_x, corpus= corpus)
predicted_df

predicted_df[predicted_df['First_prediction'] != predicted_df['CorrectLabel']]

"""### importing the phy and chm datasets """

chm_data = pd.read_csv('data-chm.csv')
phy_data = pd.read_csv('data-phy.csv')
chm_data.rename(columns={'Q_LATEX':'Q_Latex'},inplace = True)

"""### Analysis for CHM data """

example_data,trial_data = example_trial_split(chm_data)
# exploring the example_data 
print('Number of topics covered by example data',(example_data['TopicName'].unique()).shape[0])
print('Number of Chapters covered by example data',(example_data['ChapterName'].unique()).shape[0])
print('Number of KSC covered by example data',(example_data['KSCText'].unique()).shape[0])
print('Questions lacking latex data ', sum(pd.isnull(example_data['Q_Latex'])) )



label_name= 'ChapterName'; # label based on which we need to classify the data 
merged_test_train_data= preProcessDeepLearning(example_data,trial_data,label_name) 
# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
chapter_mapping= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)
corpus ## This is final data to be used

train_x,train_y, test_x, test_y = train_test_split(corpus)

model_chm =  run_cnn_model(no_labels= no_labels, activation= 'tanh', kernel_size = 1,train_x=train_x ,test_x= test_x)

"""### Accuracy before custom pre processing - 72 %
### Accuracy of custom pre processed data - 80 %
"""

predicted_df = make_pred(model_chm,test_x= test_x, corpus= corpus)
predicted_df

predicted_df[predicted_df['First_prediction'] != predicted_df['CorrectLabel']]

"""### Topics not correctly classified belong to very silimar other topics, some are even same with slight spelling differences, eg Alcohol, Phenols and Ethers	and Alcohols, Phenols and Ethers

### Analysis for Phy data
"""

phy_data.rename(columns={'Q_LATEX':'Q_Latex'},inplace = True)
example_data,trial_data = example_trial_split(phy_data)



# exploring the example_data 
print('Number of topics covered by example data',(example_data['TopicName'].unique()).shape[0])
print('Number of Chapters covered by example data',(example_data['ChapterName'].unique()).shape[0])
print('Number of KSC covered by example data',(example_data['KSCText'].unique()).shape[0])
print('Questions lacking latex data ', sum(pd.isnull(example_data['Q_Latex'])) )

merged_test_train_data=preProcessDeepLearning(example_data,trial_data,'ChapterName')

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
chapter_mapping= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)
corpus ## This is final data to be used

train_x,train_y, test_x, test_y = train_test_split(corpus)

model_phy =  run_cnn_model(no_labels= no_labels, activation= 'tanh', kernel_size = 1,train_x=train_x ,test_x= test_x)

pred_df = make_pred(model_phy,test_x,corpus)
pred_df

"""### Validation accuracy is stuck at 36 % with sigmoid filter, accuracy around 60% with tanh

### Doing analysis for total dataset

### Predicting Chapter
"""

total_data= pd.read_csv('total_data.csv')
total_data.rename(columns={'Q_LATEX':'Q_Latex'},inplace = True)
example_data,trial_data = example_trial_split(total_data)



# exploring the example_data 
print('Number of topics covered by example data',(example_data['TopicName'].unique()).shape[0])
print('Number of Chapters covered by example data',(example_data['ChapterName'].unique()).shape[0])
print('Number of KSC covered by example data',(example_data['KSCText'].unique()).shape[0])
print('Questions lacking latex data ', sum(pd.isnull(example_data['Q_Latex'])) )
total_data

total_data.rename(columns={'Q_LATEX':'Q_Latex'},inplace = True)
example_data,trial_data = example_trial_split(total_data)



# exploring the example_data 
print('Number of topics covered by example data',(example_data['TopicName'].unique()).shape[0])
print('Number of Chapters covered by example data',(example_data['ChapterName'].unique()).shape[0])
print('Number of KSC covered by example data',(example_data['KSCText'].unique()).shape[0])
print('Questions lacking latex data ', sum(pd.isnull(example_data['Q_Latex'])) )

label_name = 'ChapterName'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
chapter_mapping= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)
corpus ## This is final data to be used

train_x,train_y, test_x, test_y = train_test_split(corpus)

model_total_chapter = run_cnn_model(no_labels= no_labels, activation= 'tanh', kernel_size = 1,train_x=train_x ,test_x= test_x,train_test= train_test)

"""### Predicting KSC of question, by first predicting chapterName and then KSC """

chapter_model = model
predictions= model.predict(Xtest,verbose= 0 )
first_predictions= np.argmax(predictions,axis= 1).tolist()
test_corpus = corpus[corpus['split'] == 'test']
correct_code = test_corpus['Chapter_code'].tolist()
correct_labels = [chapter_mapping[chapter_mapping['Chapter_code']== pred_label]['label'].tolist()[0]
                          for pred_label in correct_code ]
first_predicted_labels = [chapter_mapping[chapter_mapping['Chapter_code']== pred_label]['label'].tolist()[0]
                          for pred_label in first_predictions ]
first_predicted_labels[0:10]

test_corpus['First_prediction'] = first_predicted_labels
test_corpus['ChapterName'] = correct_labels
test_corpus[test_corpus['First_prediction'] == test_corpus['ChapterName']]

"""### Training on biology data for KSC """

merged_test_train_data = example_data.append(trial_data)
merged_test_train_data

example_data['split']= 'train'
test_data = trial_data
test_data['split'] = 'test'
merged_test_train_data = example_data.append(trial_data)
merged_test_train_data

print('Number of topics covered by example data',(example_data['TopicName'].unique()).shape[0])
print('Number of Chapters covered by example data',(example_data['ChapterName'].unique()).shape[0])
print('Number of KSC covered by example data',(merged_test_train_data['KSCText'].unique()).shape[0])
print('Questions lacking latex data ', sum(pd.isnull(example_data['Q_Latex'])) )

"""### Some of the KSC around 20 are not even present in the example data """

merged_test_train_data =merged_test_train_data[['Q_Latex','KSCText','split']]
merged_test_train_data.rename(columns = {'Q_Latex':'sentence',	'KSCText':'label'}, inplace = True)
uniq_chapte_list = merged_test_train_data['label'].unique().tolist()
merged_test_train_data['KSC_code'] = [uniq_chapte_list.index(chapterName) for chapterName in merged_test_train_data['label'].tolist()] 

corpus= merged_test_train_data
ksc_mapping= corpus[['label','KSC_code']]
corpus['label'] = corpus['KSC_code']

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing
train_x = list(corpus[corpus.split=='train'].sentence)
train_y = np.array(corpus[corpus.split=='train'].label)
print(len(train_x))
print(len(train_y))

test_x = list(corpus[corpus.split=='test'].sentence)
test_y = np.array(corpus[corpus.split=='test'].label)

print('Text Before Pre processing - ',train_x[3])

train_x= preProcess(train_x)
test_x  = preProcess(test_x)

print('Text After Pre processing - ',train_x[3])

print(len(test_x))
print(len(test_y))

from tensorflow.keras import regularizers
from tensorflow.keras.constraints import MaxNorm

def define_model(filters = 100, kernel_size = 3, activation='relu', input_dim = None, output_dim=300, max_length = None, no_labels = 3 ) :
    
    model = tf.keras.models.Sequential([
        tf.keras.layers.Embedding(input_dim=vocab_size, 
                                  output_dim=output_dim, 
                                  input_length=max_length, 
                                  input_shape=(max_length, )),
        
        tf.keras.layers.Conv1D(filters=filters, kernel_size = kernel_size, activation = activation, 
                               # set 'axis' value to the first and second axis of conv1D weights (rows, cols)
                               kernel_constraint= MaxNorm( max_value=3, axis=[0,1])),
        
        tf.keras.layers.MaxPool1D(2),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(10, activation=activation, 
                              # set axis to 0 to constrain each weight vector of length (input_dim,) in dense layer
                              kernel_constraint = MaxNorm( max_value=3, axis=0)),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(units=no_labels, activation='softmax')
    ])
    
    model.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
#     model.summary()
    return model

# Parameter Initialization
trunc_type='post'
padding_type='post'
oov_tok = "<UNK>"
activation = 'tanh'
filters = 100
kernel_size = 1

columns = ['Activation', 'Filters', 'Acc']
record = pd.DataFrame(columns = columns)


# encode data using
# Cleaning and Tokenization
tokenizer = Tokenizer(oov_token=oov_tok)
tokenizer.fit_on_texts(train_x)

# Turn the text into sequence
training_sequences = tokenizer.texts_to_sequences(train_x)
test_sequences = tokenizer.texts_to_sequences(test_x)

max_len = max_length(training_sequences)

# Pad the sequence to have the same size
Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)
Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)

word_index = tokenizer.word_index
vocab_size = len(word_index)+1

# Define the input shape
model = define_model(filters, kernel_size, activation, input_dim=vocab_size, max_length=max_len,no_labels = no_labels)
  # Train the model
model.fit(Xtrain, train_y, batch_size=50, epochs=60, verbose=2, callbacks=[callbacks], validation_data=(Xtest, test_y))

# evaluate the model
loss, acc = model.evaluate(Xtest, test_y, verbose=0)
print('Test Accuracy: {}'.format(acc*100))

parameters = [activation, kernel_size]
entries = parameters + [acc]

temp = pd.DataFrame([entries], columns=columns)
record = record.append(temp, ignore_index=True)
print()
print(record)
print()

"""### We have very low accuracy for KSC, this seems to be due to lack of KSC data in our dataset """

### doing Topic  and subject classification 

total_data.rename(columns={'Q_LATEX':'Q_Latex'},inplace = True)
example_data = total_data[total_data.UseAs == 'Example']
print('number of example data are', example_data.shape[0])
trial_data = total_data[total_data.UseAs == 'Trial']
print('number of trial data are', trial_data.shape[0])


trial_data.to_csv('trial_data_total.csv')
example_data.to_csv('example_data_total.csv')


# exploring the example_data 
print('Number of topics covered by example data',(example_data['TopicName'].unique()).shape[0])
print('Number of Chapters covered by example data',(example_data['ChapterName'].unique()).shape[0])
print('Number of KSC covered by example data',(example_data['KSCText'].unique()).shape[0])
print('Questions lacking latex data ', sum(pd.isnull(example_data['Q_Latex'])) )

label_name = 'SubjectName'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
chapter_mapping= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)
corpus ## This is final data to be used

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing
train_x = list(corpus[corpus.split=='train'].sentence)
train_y = np.array(corpus[corpus.split=='train'].label)
print(len(train_x))
print(len(train_y))

test_x = list(corpus[corpus.split=='test'].sentence)
test_y = np.array(corpus[corpus.split=='test'].label)

print('Text Before Pre processing - ',train_x[4])

train_x= preProcess(train_x)
test_x  = preProcess(test_x)

print('Text After Pre processing - ',train_x[4])

print(len(test_x))
print(len(test_y))
print('Number of labels', no_labels)

model_total_subject = run_cnn_model(no_labels= no_labels, activation= 'tanh', kernel_size = 1,train_x=train_x ,test_x= test_x,train_test= train_test)

pred_df = make_pred(model_total_subject,test_x,corpus)
pred_df

"""### We are able to get an accuracy of >99% for predicting the subject

### Doing predictions for Topics now
"""

### doing Topic  and subject classification 

merged_test_train_data =merged_test_train_data[['Q_Latex','TopicName','split']]
merged_test_train_data.rename(columns = {'Q_Latex':'sentence',	'TopicName':'label'}, inplace = True)
uniq_chapte_list = merged_test_train_data['label'].unique().tolist()
merged_test_train_data['Topic_code'] = [uniq_chapte_list.index(chapterName) for chapterName in merged_test_train_data['label'].tolist()] 

corpus= merged_test_train_data
topic_mapping= corpus[['label','Topic_code']]
corpus['label'] = corpus['Topic_code']
no_labels = len(corpus['label'].unique().tolist())
corpus

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing
train_x = list(corpus[corpus.split=='train'].sentence)
train_y = np.array(corpus[corpus.split=='train'].label)
print(len(train_x))
print(len(train_y))

test_x = list(corpus[corpus.split=='test'].sentence)
test_y = np.array(corpus[corpus.split=='test'].label)

print('Text Before Pre processing - ',train_x[4])

train_x= preProcess(train_x)
test_x  = preProcess(test_x)

print('Text After Pre processing - ',train_x[4])

print(len(test_x))
print(len(test_y))
print('Number of labels', no_labels)

# Parameter Initialization
trunc_type='post'
padding_type='post'
oov_tok = "<UNK>"
activation = 'tanh'
filters = 100
kernel_size = 1

columns = ['Activation', 'Filters', 'Acc']
record = pd.DataFrame(columns = columns)


# encode data using
# Cleaning and Tokenization
tokenizer = Tokenizer(oov_token=oov_tok)
tokenizer.fit_on_texts(train_x)

# Turn the text into sequence
training_sequences = tokenizer.texts_to_sequences(train_x)
test_sequences = tokenizer.texts_to_sequences(test_x)

max_len = max_length(training_sequences)

# Pad the sequence to have the same size
Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)
Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)

word_index = tokenizer.word_index
vocab_size = len(word_index)+1

# Define the input shape
model = define_model(filters, kernel_size, activation, input_dim=vocab_size, max_length=max_len,no_labels = no_labels)
  # Train the model
model.fit(Xtrain, train_y, batch_size=50, epochs=60, verbose=2, callbacks=[callbacks], validation_data=(Xtest, test_y))

# evaluate the model
loss, acc = model.evaluate(Xtest, test_y, verbose=0)
print('Test Accuracy: {}'.format(acc*100))

parameters = [activation, kernel_size]
entries = parameters + [acc]

temp = pd.DataFrame([entries], columns=columns)
record = record.append(temp, ignore_index=True)
print()
print(record)
print()

topic_model = model 
predictions= model.predict(Xtest,verbose= 0 )
first_predictions= np.argmax(predictions,axis= 1).tolist()
test_corpus = corpus[corpus['split'] == 'test']
correct_code = test_corpus['Topic_code'].tolist()
correct_labels = [topic_mapping[topic_mapping['Topic_code']== pred_label]['label'].tolist()[0]
                          for pred_label in correct_code ]
first_predicted_labels = [topic_mapping[topic_mapping['Topic_code']== pred_label]['label'].tolist()[0]
                          for pred_label in first_predictions ]
first_predicted_labels[0:10]

test_corpus['First_prediction'] = first_predicted_labels
test_corpus['TopicName'] = correct_labels
test_corpus[test_corpus['First_prediction'] == test_corpus['TopicName']]

test_corpus[test_corpus['First_prediction'] != test_corpus['TopicName']]

"""### SUMMARAY 
### Accuracy for Subject = 99%
### Accuracy for Topic = 73 %
### Accuract for chapter = 72%
### accuracy for KSC = 12 %

### Accuracy for top 5 KSC 
### predict KSC on basis of chapter predicted, use KSC only present in that chapter
### Pick a simple NN and see how it performs

## Using a 2 layer NN for prediction
"""

model_NN = simple_NN_model();
model_NN.summary()

"""### Analysis for total dataset"""

# load total dataset 
total_data = pd.read_csv('total_data.csv')
trial_data, example_data = example_trial_split(total_data)

label_name = 'ChapterName'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
chapter_mapping= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)

## Do pre processing 

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing
train_x,train_y, test_x, test_y = train_test_split(corpus)


train_x= preProcess(train_x)
test_x  = preProcess(test_x)

print('Text After Pre processing - ',train_x[3])


tokenizer_total = create_tokenizer(train_x)
    
# encode data using freq mode
Xtrain = tokenizer_total.texts_to_matrix(train_x, mode='freq')
Xtest = tokenizer_total.texts_to_matrix(test_x, mode='freq')

model_chapter_total = simple_NN_model(no_labels,len(Xtest[0]))
batch_size = 50
epochs = 60
verbose =2
model_chapter_total.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model_chapter_total.fit(Xtrain, train_y, batch_size, epochs, verbose,callbacks=[callbacks], validation_data=(Xtest, test_y))


loss, acc = model_chapter_total.evaluate(Xtest, test_y, verbose=0)
print('Test Accuracy: {}'.format(acc*100))

predictions= model_chapter_total.predict(Xtest,verbose= 0 )
first_predictions= np.argmax(predictions,axis= 1).tolist()
first_predictions[0:10]
test_corpus = corpus[corpus['split'] == 'test']
correct_code = test_corpus['label'].tolist()
correct_labels = [chapter_mapping[chapter_mapping['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in correct_code ]
first_predicted_labels = [chapter_mapping[chapter_mapping['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in first_predictions ]
first_predicted_labels[0:10]

test_corpus['First_prediction'] = first_predicted_labels
test_corpus['labelName'] = correct_labels
incorrect_chapter_pred = test_corpus[test_corpus['First_prediction'] != test_corpus['labelName']]
incorrect_chapter_pred

"""### This model gives us a better accuracy of 80%, which is 2% better than without math data """

print('Top misclassified labels')
incorrect_chapter_pred.groupby('labelName').count().sort_values(by = 'sentence', ascending = False).head(10).sentence

"""### using NN to predict KSC"""

label_name = 'KSCText'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
KSC_mapping= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)


## Do pre processing 

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing
train_x,train_y, test_x, test_y = train_test_split(corpus)

train_x= preProcess(train_x)
test_x  = preProcess(test_x)

print('Text After Pre processing - ',train_x[3])

no_labels = len(corpus['label'].unique().tolist())
print('No of KSC are',no_labels)


tokenizer_total = create_tokenizer(train_x)
    
# encode data using freq mode
Xtrain = tokenizer_total.texts_to_matrix(train_x, mode='freq')
Xtest = tokenizer_total.texts_to_matrix(test_x, mode='freq')


# running model and doing predictions 
model_KSC_total = simple_NN_model(no_labels,len(Xtest[0]))
batch_size = 50
epochs = 60
verbose =2
model_KSC_total.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model_KSC_total.fit(Xtrain, train_y, batch_size, epochs, verbose,callbacks=[callbacks], validation_data=(Xtest, test_y))
loss, acc = model_KSC_total.evaluate(Xtest, test_y, verbose=0)
print('Test Accuracy: {}'.format(acc*100))





predictions= model_KSC_total.predict(Xtest,verbose= 0 )
first_predictions= np.argmax(predictions,axis= 1).tolist()
first_predictions[0:10]
test_corpus = corpus[corpus['split'] == 'test']
correct_code = test_corpus['label'].tolist()
correct_labels = [KSC_mapping[KSC_mapping['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in correct_code ]
first_predicted_labels = [KSC_mapping[KSC_mapping['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in first_predictions ]
first_predicted_labels[0:10]

test_corpus['First_prediction'] = first_predicted_labels
test_corpus['labelName'] = correct_labels
incorrect_ksc_pred = test_corpus[test_corpus['First_prediction'] != test_corpus['labelName']]
print('Top misclassified  KSC labels')
incorrect_ksc_pred.groupby('labelName').count().sort_values(by = 'sentence', ascending = False).head(10).sentence

"""### most of the incorrrectly predicted KSC belong from math subject

### Using NN to predict subject
"""

label_name = 'SubjectName'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
subject_mapping= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)


## Do pre processing 

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing
train_x,train_y, test_x, test_y = train_test_split(corpus)

train_x= preProcess(train_x)
test_x  = preProcess(test_x)

print('Text After Pre processing - ',train_x[3])

no_labels = len(corpus['label'].unique().tolist())
print('No of Subject are',no_labels)


tokenizer_total = create_tokenizer(train_x)
    
# encode data using freq mode
Xtrain = tokenizer_total.texts_to_matrix(train_x, mode='freq')
Xtest = tokenizer_total.texts_to_matrix(test_x, mode='freq')

model_subjcet_total = simple_NN_model(no_labels,len(Xtest[0]))
batch_size = 50
epochs = 60
verbose =2
model_subjcet_total.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model_subjcet_total.fit(Xtrain, train_y, batch_size, epochs, verbose,callbacks=[callbacks], validation_data=(Xtest, test_y))

loss, acc = model_subjcet_total.evaluate(Xtest, test_y, verbose=0)
print('Test Accuracy: {}'.format(acc*100))

"""### Using all three models to make prediction"""

chapter_mapping= chapter_mapping.drop_duplicates(subset ="label")
KSC_mapping= KSC_mapping.drop_duplicates(subset ="label")
subject_mapping= subject_mapping.drop_duplicates(subset ="label")

pred_seq_wise = []
for i in range(0, len(Xtest)-1):
  x_test = Xtest[i:i +1]
  subject_pred= model_subjcet_total.predict(x_test)
  subject_pred= np.argmax(subject_pred,axis= 1).tolist()
  subject_pred=subject_pred[0]

  pred_subject_label = subject_mapping[subject_mapping['label_code'] == subject_pred].label.tolist()[0]
  if(pred_subject_label != trial_data.SubjectName.tolist()[i]):
    pred_seq_wise.append(0) ;
  else :
    chapter_pred= model_chapter_total.predict(x_test)
    pred_prob = chapter_mapping
    pred_prob['Probability']=chapter_pred[0]
    valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
    pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]
    if(pred_chapter_label != trial_data.ChapterName.tolist()[i]):
      pred_seq_wise.append(0) ;
    else:
      KSC_pred = model_KSC_total.predict(x_test)
      pred_prob = KSC_mapping
      pred_prob['Probability']=KSC_pred[0]
      valid_KSC = trial_data[trial_data['ChapterName']==pred_chapter_label ].KSCText.unique()
      try:
        correct_KSC = trial_data.KSCText.tolist()[i]

        pred_KSC_label_first = pred_prob[pred_prob['label'].isin(valid_KSC)].sort_values('Probability',ascending=False).label.tolist()[0]
        pred_KSC_label_second = pred_prob[pred_prob['label'].isin(valid_KSC)].sort_values('Probability',ascending=False).label.tolist()[1]
        pred_KSC_label_third = pred_prob[pred_prob['label'].isin(valid_KSC)].sort_values('Probability',ascending=False).label.tolist()[2]



        if(pred_KSC_label_first == correct_KSC or pred_KSC_label_second == correct_KSC or pred_KSC_label_third == correct_KSC):
          result = 1;
          pred_seq_wise.append(1) ;
        else :
          result = 0 ;
          pred_seq_wise.append(0) ;
      except :
        try:
          if(pred_KSC_label_first == correct_KSC or pred_KSC_label_second == correct_KSC):
            result = 1;
            pred_seq_wise.append(1) ;
          else :
            result = 0 ;
            pred_seq_wise.append(0) ;
            
        except :
            if(pred_KSC_label_first == correct_KSC):
              result = 1;
              pred_seq_wise.append(1) ;
            else :
              result = 0 ;
              pred_seq_wise.append(0) ;

print('Accuracy with top 3 KSC is',sum(pred_seq_wise)/len(pred_seq_wise) * 100)

"""### see at KSC cluster level 
### do for math data also 
### Try simpler NN

### Analysis for math data
"""

# load total dataset 
mth_data = pd.read_csv('data-mth.csv')
mth_data.rename(columns={'Q_LATEX':'Q_Latex'},inplace = True)


trial_data, example_data = example_trial_split(mth_data)




label_name = 'ChapterName'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
chapter_mapping_math= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)


train_x,train_y, test_x, test_y = train_test_split(corpus)

train_x= preProcess(train_x)
test_x  = preProcess(test_x)

print('Text After Pre processing - ',train_x[3])

no_labels = len(corpus['label'].unique().tolist())
print('No of Chapters are',no_labels)

tokenizer_math = create_tokenizer(train_x)
    
# encode data using freq mode
Xtrain = tokenizer_math.texts_to_matrix(train_x, mode='freq')
Xtest = tokenizer_math.texts_to_matrix(test_x, mode='freq')

model_chapter_math = simple_NN_model(no_labels,len(Xtest[0]))
batch_size = 50
epochs = 60
verbose =2
model_chapter_math.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model_chapter_math.fit(Xtrain, train_y, batch_size, epochs, verbose,callbacks=[callbacks], validation_data=(Xtest, test_y))

# doing predictions

predictions= model_chapter_math.predict(Xtest,verbose= 0 )
first_predictions= np.argmax(predictions,axis= 1).tolist()
test_corpus = corpus[corpus['split'] == 'test']
correct_code = test_corpus['label'].tolist()
correct_labels = [chapter_mapping_math[chapter_mapping_math['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in correct_code ]
first_predicted_labels = [chapter_mapping_math[chapter_mapping_math['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in first_predictions ]
first_predicted_labels[0:10]

test_corpus['First_prediction'] = first_predicted_labels
test_corpus['labelName'] = correct_labels
test_corpus[test_corpus['First_prediction'] != test_corpus['labelName']]

"""#### doing Chapter level prediction

#### Doing KSC wise prediction
"""

# load total dataset 

label_name = 'KSCText'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
KSC_mapping_math= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)

## Do pre processing 

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing

train_y = np.array(corpus[corpus.split=='train'].label)

test_y = np.array(corpus[corpus.split=='test'].label)

no_labels = len(corpus['label'].unique().tolist())
print('No of KSC are',no_labels)



model_KSC_math = simple_NN_model(no_labels,len(Xtest[0]))
batch_size = 50
epochs = 60
verbose =2
model_KSC_math.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model_KSC_math.fit(Xtrain, train_y, batch_size, epochs, verbose,callbacks=[callbacks], validation_data=(Xtest, test_y))


predictions= model_KSC_math.predict(Xtest,verbose= 0 )
first_predictions= np.argmax(predictions,axis= 1).tolist()
test_corpus = corpus[corpus['split'] == 'test']
correct_code = test_corpus['label'].tolist()
correct_labels = [KSC_mapping_math[KSC_mapping_math['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in correct_code ]
first_predicted_labels = [KSC_mapping_math[KSC_mapping_math['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in first_predictions ]

test_corpus['First_prediction'] = first_predicted_labels
test_corpus['labelName'] = correct_labels
test_corpus[test_corpus['First_prediction'] != test_corpus['labelName']]

"""#### accuracy within KSC in math is about 42 %

## Doing chapter and KSC prediction for chm, bio and physis data also using 2 layer NN

### For biology data
### Chapter prediction
"""

bio_data= pd.read_csv('data-bio.csv')

trial_data, example_data = example_trial_split(bio_data)

label_name = 'ChapterName'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
chapter_mapping_bio= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)

## Do pre processing 

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing
train_x,train_y, test_x, test_y = train_test_split(corpus)

train_x= preProcess(train_x)
test_x  = preProcess(test_x)

print('Text After Pre processing - ',train_x[3])


no_labels = len(corpus['label'].unique().tolist())
print('No of Chapter are',no_labels)


# tokenizing and training 
tokenizer_bio = create_tokenizer(train_x) 
    
# encode data using freq mode
Xtrain = tokenizer_bio.texts_to_matrix(train_x, mode='freq')
Xtest = tokenizer_bio.texts_to_matrix(test_x, mode='freq')

model_chapter_bio = simple_NN_model(no_labels,len(Xtest[0]))
batch_size = 50
epochs = 60
verbose =2
model_chapter_bio.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model_chapter_bio.fit(Xtrain, train_y, batch_size, epochs, verbose,callbacks=[callbacks], validation_data=(Xtest, test_y))



predictions= model_chapter_bio.predict(Xtest,verbose= 0 )
first_predictions= np.argmax(predictions,axis= 1).tolist()
first_predictions[0:10]
test_corpus = corpus[corpus['split'] == 'test']
correct_code = test_corpus['label'].tolist()
correct_labels = [chapter_mapping_bio[chapter_mapping_bio['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in correct_code ]
first_predicted_labels = [chapter_mapping_bio[chapter_mapping_bio['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in first_predictions ]
first_predicted_labels[0:10]

test_corpus['First_prediction'] = first_predicted_labels
test_corpus['labelName'] = correct_labels
test_corpus[test_corpus['First_prediction'] != test_corpus['labelName']]

"""### Bio KSC prediction"""

label_name = 'KSCText'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
KSC_mapping_bio= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)
corpus ## This is final data to be used 

## Do pre processing 

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing

train_y = np.array(corpus[corpus.split=='train'].label)


test_y = np.array(corpus[corpus.split=='test'].label)



no_labels = len(corpus['label'].unique().tolist())
print('No of KSC are',no_labels)


# tokenizing and training 
#tokenizer = create_tokenizer(train_x)
    

model_KSC_bio = simple_NN_model(no_labels,len(Xtest[0]))
batch_size = 50
epochs = 60
verbose =2
model_KSC_bio.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model_KSC_bio.fit(Xtrain, train_y, batch_size, epochs, verbose,callbacks=[callbacks], validation_data=(Xtest, test_y))


loss, acc = model_KSC_bio.evaluate(Xtest, test_y, verbose=0)
print('Test Accuracy: {}'.format(acc*100))


predictions= model_chapter_bio.predict(Xtest,verbose= 0 )
first_predictions= np.argmax(predictions,axis= 1).tolist()
first_predictions[0:10]
test_corpus = corpus[corpus['split'] == 'test']
correct_code = test_corpus['label'].tolist()
correct_labels = [KSC_mapping_bio[KSC_mapping_bio['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in correct_code ]
first_predicted_labels = [KSC_mapping_bio[KSC_mapping_bio['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in first_predictions ]

test_corpus['First_prediction'] = first_predicted_labels
test_corpus['labelName'] = correct_labels
test_corpus[test_corpus['First_prediction'] != test_corpus['labelName']]

"""### Chemistry Chapter Prediction"""

chm_data= pd.read_csv('data-chm.csv')
chm_data.rename(columns = {'Q_LATEX':'Q_Latex'}, inplace = True)


trial_data, example_data = example_trial_split(chm_data)


label_name = 'ChapterName'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
chapter_mapping_chm=  merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)


## Do pre processing 

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing
train_x,train_y, test_x, test_y = train_test_split(corpus)


train_x= preProcess(train_x)
test_x  = preProcess(test_x)

print('Text After Pre processing - ',train_x[3])

print(len(test_x))
print(len(test_y))

no_labels = len(corpus['label'].unique().tolist())
print('No of Chapter are',no_labels)



# tokenizing and training 
tokenizer_chm = create_tokenizer(train_x)
    
# encode data using freq mode
Xtrain = tokenizer_chm.texts_to_matrix(train_x, mode='freq')
Xtest = tokenizer_chm.texts_to_matrix(test_x, mode='freq')

model_chapter_chm = simple_NN_model(no_labels,len(Xtest[0]))
batch_size = 50
epochs = 60
verbose =2
model_chapter_chm.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model_chapter_chm.fit(Xtrain, train_y, batch_size, epochs, verbose,callbacks=[callbacks], validation_data=(Xtest, test_y))


loss, acc = model_chapter_chm.evaluate(Xtest, test_y, verbose=0)
print('Test Accuracy: {}'.format(acc*100))


predictions= model_chapter_chm.predict(Xtest,verbose= 0 )
first_predictions= np.argmax(predictions,axis= 1).tolist()
first_predictions[0:10]
test_corpus = corpus[corpus['split'] == 'test']
correct_code = test_corpus['label'].tolist()
correct_labels = [chapter_mapping_chm[chapter_mapping_chm['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in correct_code ]
first_predicted_labels = [chapter_mapping_chm[chapter_mapping_chm['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in first_predictions ]
first_predicted_labels[0:10]

test_corpus['First_prediction'] = first_predicted_labels
test_corpus['labelName'] = correct_labels
test_corpus[test_corpus['First_prediction'] != test_corpus['labelName']]

"""### CHM KSC analysis """

label_name = 'KSCText'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
KSC_mapping_chm=  merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)
  

## Do pre processing 
train_y = np.array(corpus[corpus.split=='train'].label)

test_y = np.array(corpus[corpus.split=='test'].label)


no_labels = len(corpus['label'].unique().tolist())
print('No of KSC are',no_labels)


# tokenizing and training 
#tokenizer = create_tokenizer(train_x)
    
# encode data using freq mode

model_KSC_chm = simple_NN_model(no_labels,len(Xtest[0]))
batch_size = 50
epochs = 60
verbose =2
model_KSC_chm.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model_KSC_chm.fit(Xtrain, train_y, batch_size, epochs, verbose,callbacks=[callbacks], validation_data=(Xtest, test_y))


loss, acc = model_KSC_chm.evaluate(Xtest, test_y, verbose=0)
print('Test Accuracy: {}'.format(acc*100))


predictions= model_chapter_chm.predict(Xtest,verbose= 0 )
first_predictions= np.argmax(predictions,axis= 1).tolist()
first_predictions[0:10]
test_corpus = corpus[corpus['split'] == 'test']
correct_code = test_corpus['label'].tolist()
correct_labels = [KSC_mapping_chm[KSC_mapping_chm['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in correct_code ]
first_predicted_labels = [KSC_mapping_chm[KSC_mapping_chm['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in first_predictions ]
first_predicted_labels[0:10]

test_corpus['First_prediction'] = first_predicted_labels
test_corpus['labelName'] = correct_labels
test_corpus[test_corpus['First_prediction'] != test_corpus['labelName']]

"""### Physics chapter prediction"""

phy_data= pd.read_csv('data-phy.csv')
phy_data.rename(columns = {'Q_LATEX':'Q_Latex'}, inplace = True)


trial_data, example_data = example_trial_split(phy_data)


label_name = 'ChapterName'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
chapter_mapping_phy =   merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)

train_x,train_y, test_x, test_y = train_test_split(corpus)

train_x= preProcess(train_x)
test_x  = preProcess(test_x)


no_labels = len(corpus['label'].unique().tolist())
print('No of Chapter are',no_labels)


# tokenizing and training 
tokenizer_phy = create_tokenizer(train_x)
    
# encode data using freq mode
Xtrain = tokenizer_phy.texts_to_matrix(train_x, mode='freq')
Xtest = tokenizer_phy.texts_to_matrix(test_x, mode='freq')

model_chapter_phy = simple_NN_model(no_labels,len(Xtest[0]))
batch_size = 50
epochs = 60
verbose =2
model_chapter_phy.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model_chapter_phy.fit(Xtrain, train_y, batch_size, epochs, verbose,callbacks=[callbacks], validation_data=(Xtest, test_y))


loss, acc = model_chapter_phy.evaluate(Xtest, test_y, verbose=0)
print('Test Accuracy: {}'.format(acc*100))


predictions= model_chapter_phy.predict(Xtest,verbose= 0 )
first_predictions= np.argmax(predictions,axis= 1).tolist()
first_predictions[0:10]
test_corpus = corpus[corpus['split'] == 'test']
correct_code = test_corpus['label'].tolist()
correct_labels = [chapter_mapping_phy[chapter_mapping_phy['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in correct_code ]
first_predicted_labels = [chapter_mapping_phy[chapter_mapping_phy['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in first_predictions ]
first_predicted_labels[0:10]

test_corpus['First_prediction'] = first_predicted_labels
test_corpus['labelName'] = correct_labels
test_corpus[test_corpus['First_prediction'] != test_corpus['labelName']]

"""### Physics KSC prediction"""

label_name = 'KSCText'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
KSC_mapping_phy =   merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)

## Do pre processing 

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing
train_y = np.array(corpus[corpus.split=='train'].label)

test_y = np.array(corpus[corpus.split=='test'].label)

no_labels = len(corpus['label'].unique().tolist())
print('No of KSC are',no_labels)



# tokenizing and training 
#tokenizer = create_tokenizer(train_x)
    
model_KSC_phy = simple_NN_model(no_labels,len(Xtest[0]))
batch_size = 50
epochs = 60
verbose =2
model_KSC_phy.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
model_KSC_phy.fit(Xtrain, train_y, batch_size, epochs, verbose,callbacks=[callbacks], validation_data=(Xtest, test_y))


loss, acc = model_KSC_phy.evaluate(Xtest, test_y, verbose=0)
print('Test Accuracy: {}'.format(acc*100))

predictions= model_KSC_phy.predict(Xtest,verbose= 0 )
first_predictions= np.argmax(predictions,axis= 1).tolist()
first_predictions[0:10]
test_corpus = corpus[corpus['split'] == 'test']
correct_code = test_corpus['label'].tolist()
correct_labels = [KSC_mapping_phy[KSC_mapping_phy['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in correct_code ]
first_predicted_labels = [KSC_mapping_phy[KSC_mapping_phy['label_code']== pred_label]['label'].tolist()[0]
                          for pred_label in first_predictions ]
first_predicted_labels[0:10]

test_corpus['First_prediction'] = first_predicted_labels
test_corpus['labelName'] = correct_labels
test_corpus[test_corpus['First_prediction'] != test_corpus['labelName']]

"""## Use all 9 models to make prediction"""

chapter_mapping_total= chapter_mapping.drop_duplicates(subset ="label")
KSC_mapping_total= KSC_mapping.drop_duplicates(subset ="label")
subject_mapping_total= subject_mapping.drop_duplicates(subset ="label")

chapter_mapping_phy= chapter_mapping_phy.drop_duplicates(subset ="label")
KSC_mapping_phy= KSC_mapping_phy.drop_duplicates(subset ="label")


chapter_mapping_chm= chapter_mapping_chm.drop_duplicates(subset ="label")
KSC_mapping_chm= KSC_mapping_chm.drop_duplicates(subset ="label")


chapter_mapping_math= chapter_mapping_math.drop_duplicates(subset ="label")
KSC_mapping_math= KSC_mapping_math.drop_duplicates(subset ="label")


chapter_mapping_bio= chapter_mapping_bio.drop_duplicates(subset ="label")
KSC_mapping_bio= KSC_mapping_bio.drop_duplicates(subset ="label")


## all trained models 
model_KSC_phy
model_KSC_math
model_KSC_bio
model_KSC_chm

model_chapter_phy
model_chapter_math
model_chapter_bio
model_chapter_chm


model_subjcet_total



# all tokenizers 

tokenizer_phy
tokenizer_chm
tokenizer_bio
tokenizer_math
tokenizer_total

total_data = pd.read_csv('total_data.csv')
trial_data, example_data = example_trial_split(total_data)

label_name = 'ChapterName'
merged_test_train_data=preProcessDeepLearning(example_data,trial_data,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 
chapter_mapping= merged_test_train_data[['label','label_code']]

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)

## Do pre processing 

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing
train_x,train_y, test_x, test_y = train_test_split(corpus)


train_x= preProcess(train_x)
test_x  = preProcess(test_x)

print('Text After Pre processing - ',train_x[3])


tokenizer_total = create_tokenizer(train_x)
    
# encode data using freq mode
Xtrain = tokenizer_total.texts_to_matrix(train_x, mode='freq')
Xtest = tokenizer_total.texts_to_matrix(test_x, mode='freq')

pred_seq_wise = []
for i in range(0,len(Xtest)-1):
  ques_text = test_x[i:i +1]
  test_ques = tokenizer_total.texts_to_matrix(ques_text, mode='freq')

  subject_pred= model_subjcet_total.predict(test_ques)
  subject_pred= np.argmax(subject_pred,axis= 1).tolist()
  subject_pred=subject_pred[0]
  pred_subject_label = subject_mapping[subject_mapping['label_code'] == subject_pred].label.tolist()[0]
  if(pred_subject_label != trial_data.SubjectName.tolist()[i]):
    pred_seq_wise.append(0) ;

  else :
    if(pred_subject_label == 'Biology'):
      test_ques = tokenizer_bio.texts_to_matrix(ques_text, mode='freq')
      chapter_pred= model_chapter_bio.predict(test_ques)
      ksc_model = model_KSC_bio
      pred_prob = chapter_mapping_bio
      ksc_mapping = KSC_mapping_bio
      pred_prob['Probability']=chapter_pred[0]
      valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
      pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]

    elif(pred_subject_label == 'Chemistry'): 
      test_ques = tokenizer_chm.texts_to_matrix(ques_text, mode='freq')
      chapter_pred= model_chapter_chm.predict(test_ques)
      ksc_model = model_KSC_chm
      pred_prob = chapter_mapping_chm
      ksc_mapping = KSC_mapping_chm
      pred_prob['Probability']=chapter_pred[0]
      valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
      pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]

    elif(pred_subject_label == 'Physics'):
      test_ques = tokenizer_phy.texts_to_matrix(ques_text, mode='freq')
      chapter_pred= model_chapter_phy.predict(test_ques)
      pred_prob = chapter_mapping_phy
      ksc_model = model_KSC_phy
      ksc_mapping = KSC_mapping_phy
      pred_prob['Probability']=chapter_pred[0]
      valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
      pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]

    elif(pred_subject_label == 'Maths'):
      test_ques = tokenizer_math.texts_to_matrix(ques_text, mode='freq')
      chapter_pred= model_chapter_math.predict(test_ques)
      pred_prob = chapter_mapping_math
      ksc_model = model_KSC_math
      ksc_mapping = KSC_mapping_math
      pred_prob['Probability']=chapter_pred[0]
      valid_chapters = trial_data[trial_data['SubjectName']==pred_subject_label ].ChapterName.unique()
      pred_chapter_label= pred_prob[pred_prob['label'].isin(valid_chapters)].sort_values('Probability',ascending=False).label.tolist()[0]

    if(pred_chapter_label != trial_data.ChapterName.tolist()[i]):
        pred_seq_wise.append(0) ;

    else: 
      KSC_pred = ksc_model.predict(test_ques)
      pred_prob = ksc_mapping
      pred_prob['Probability']=KSC_pred[0]
      valid_KSC = trial_data[trial_data['ChapterName']==pred_chapter_label ].KSCText.unique()
      try:
        correct_KSC = trial_data.KSCText.tolist()[i]

        pred_KSC_label_first = pred_prob[pred_prob['label'].isin(valid_KSC)].sort_values('Probability',ascending=False).label.tolist()[0]
      
        pred_KSC_label_second = pred_prob[pred_prob['label'].isin(valid_KSC)].sort_values('Probability',ascending=False).label.tolist()[1]
        pred_KSC_label_third = pred_prob[pred_prob['label'].isin(valid_KSC)].sort_values('Probability',ascending=False).label.tolist()[2]
  
        
        if(pred_KSC_label_first == correct_KSC or pred_KSC_label_second == correct_KSC or pred_KSC_label_third == correct_KSC):
          result = 1;
          pred_seq_wise.append(1) ;
        else :
          result = 0 ;
          pred_seq_wise.append(0) ;
      except :
        try:
          if(pred_KSC_label_first == correct_KSC or pred_KSC_label_second == correct_KSC):
            result = 1;
            pred_seq_wise.append(1) ;
          else :
            result = 0 ;
            pred_seq_wise.append(0) ;
            
        except :
            if(pred_KSC_label_first == correct_KSC):
              result = 1;
              pred_seq_wise.append(1) ;
            else :
              result = 0 ;
              pred_seq_wise.append(0) ;

pred_seq_wise_text = pred_seq_wise
print('Accuracy with top 3 KSC is',sum(pred_seq_wise)/len(pred_seq_wise) * 100)

"""### Using forest regression and other techniques




"""

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC


count_vect = CountVectorizer()
X_train_counts = count_vect.fit_transform(train_x)
tfidf_transformer = TfidfTransformer()
X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)
X_train_tfidf

clf = MultinomialNB().fit(X_train_tfidf, train_y)
pred_labels_nb = clf.predict(count_vect.transform(test_x))
clf= RandomForestClassifier(n_estimators=200, max_depth=5, random_state=0).fit(X_train_tfidf, train_y)
pred_labels_rfc = clf.predict(count_vect.transform(test_x))
clf = LinearSVC().fit(X_train_tfidf, train_y)
pred_labels_svc = clf.predict(count_vect.transform(test_x))
clf = LogisticRegression(random_state=0).fit(X_train_tfidf, train_y)
pred_labels_reg =  clf.predict(count_vect.transform(test_x))
print('Accuracy is with native bayes is-  ',sum(pred_labels_nb == test_y)/len(test_y))
print('Accuracy is with random forest is-  ',sum(pred_labels_rfc == test_y)/len(test_y))
print('Accuracy is with SVM is-  ',sum(pred_labels_svc == test_y)/len(test_y))
print('Accuracy is with logistic regression is-  ',sum(pred_labels_reg == test_y)/len(test_y))

"""Use 3 nearest neighbours useing Knn and see probability of falling into same cluster/chapter/subject"""

count_vect = CountVectorizer()
X_train_counts = count_vect.fit_transform(train_x)
X_train_counts

tfidf_transformer = TfidfTransformer()
X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)
X_train_tfidf

from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline

knn = KNeighborsClassifier(n_neighbors=100)
clf = knn.fit(X_train_tfidf, train_y)

X_test_counts = count_vect.transform(test_x)
# We call transform instead of fit_transform because it's already been fit
X_test_tfidf = tfidf_transformer.transform(X_test_counts)

predicted_knn = clf.predict(X_test_tfidf) ## predict nearest neighborus for test data
print('Accuracy is with Knn is-  ',sum(predicted_knn == test_y)/len(test_y))

"""## Connecting to database to get KSC cluster information"""

def getKSCMappings():
    conn = pymssql.connect('20.198.89.10', 'Speedlabsread', '$tar@Night', "speedlabs-anon")
    cursor = conn.cursor(as_dict=True)

    cursor.execute('SELECT  * FROM KSC ;')
    KSC_cluster_id_list= [];
    KSC_text_list= [];

    for row in cursor:
      KSC_cluster_id_list.append(row['KSCClusterId']);
      KSC_text_list.append( row['KSCText']);

    ksc_information_df = pd.DataFrame(list(zip(KSC_text_list,KSC_cluster_id_list)),columns = ['KSCText','ClusterId'])


    cursor.execute('SELECT  * FROM KSCCluster;')
    KSC_cluster_id_list= [];
    KSC_cluster_name_list= [];

    for row in cursor:
      KSC_cluster_id_list.append(row['KSCClusterId']);
      KSC_cluster_name_list.append( row['KSCClusterName']);


    ksc_cluster_name_info = pd.DataFrame(list(zip(KSC_cluster_name_list,KSC_cluster_id_list)),columns = ['KSCClusterName','ClusterId'])
    ksc_mappings_df = pd.merge(ksc_information_df, ksc_cluster_name_info, on="ClusterId")
    ksc_mappings_df= ksc_mappings_df.drop_duplicates(subset= 'KSCText')

    return ksc_mappings_df

"""### Calculating edit distance between KSC to use as an alternate cluster """

def getCustomKSCMappingsEdit():
  ! pip install Levenshtein

  from Levenshtein import distance as levenshtein_distance

  len(total_KSC_list)
  KSC_sim_array_edit = np.zeros((total_KSC,total_KSC), dtype=int, order='C')

  for i in range(0,total_KSC):
    for j in range(0, total_KSC):
      edit_distance = levenshtein_distance(total_KSC_list[i],total_KSC_list[j])
      KSC_sim_array_edit[i,j] = edit_distance


  custom_ksc_mapping = pd.DataFrame(total_KSC_list,columns = ['KSCText'])
  custom_ksc_mapping['KSCClusterName']= custom_ksc_mapping.index.tolist()


  for i in range(0,total_KSC):
    for j in range(i+1, total_KSC):
      edit_distance = KSC_sim_array_edit[i,j];
      if(edit_distance < 5 ):
        custom_ksc_mapping['KSCClusterName'][j] =   custom_ksc_mapping['KSCClusterName'][i];


  plt.violinplot(dataset=[KSC_sim_array_edit.flatten()])
  return custom_ksc_mapping

ksc_mappings_df = getCustomKSCMappingsEdit()

TestWithCluster = createTestWithCluster(ksc_mappings_df)

label_name = 'KSCText'
merged_test_train_data=preProcessDeepLearning(test_with_cluster,test_with_cluster,label_name)

# pass the chapter which you want as label in you data 
# it gives the merged train and test data with appropiate column nanmes 
uniq_label_list = merged_test_train_data['label'].unique().tolist()
no_labels = len(uniq_label_list)
merged_test_train_data['label_code'] = [uniq_label_list.index(label) for label in merged_test_train_data['label'].tolist()] 

corpus=  merged_test_train_data 
corpus['label'] = corpus['label_code']
corpus.drop('label_code',axis= 1, inplace = True)
print('No of unique',label_name, 'are',no_labels)

## Do pre processing 

# Separate the sentences and the labels
# Separate the sentences and the labels for training and testing

test_x = list(corpus[corpus.split=='test'].sentence)
test_y = np.array(corpus[corpus.split=='test'].label)

test_x  = preProcess(test_x)
test_x= test_x[0 : round(len(test_x)/2)]

Xtest = tokenizer_total.texts_to_matrix(test_x, mode='freq')

trial_data = test_with_cluster

# defining KSC similarity array to get similarity between KSCs using different metrics 
total_KSC = len(KSC_mapping_total)
KSC_sim_array = np.zeros((total_KSC,total_KSC), dtype=int, order='C') # smilarity between KSC based on misclassifications
total_KSC_list = KSC_mapping_total.label.tolist()

def createTestWithCluster(ksc_mappings_df):
  total_data_cluster= total_data[total_data['KSCText'].isin(ksc_mappings_df.KSCText.tolist())]
  print('Total Data  ', len(total_data))
  print('Total Data having cluster information is ', len(total_data_cluster))


  test_with_cluster = total_data_cluster[total_data_cluster.UseAs == 'Trial']
  ksc_text = test_with_cluster['KSCText']
  ksc_cluster_column= [ksc_mappings_df[ksc_mappings_df['KSCText']==ks].KSCClusterName.tolist()[0] for ks in ksc_text]
  print('Test data with cluster information', len(test_with_cluster))


  test_with_cluster['KSCClusterName']= ksc_cluster_column
  test_with_cluster.to_csv('test_with_cluster.csv')
  return test_with_cluster

pred_seq_wise_text = accuracyTopThreeKSCText()
print('Accuracy with top 3 KSC when matching with text is',sum(pred_seq_wise_text)/len(pred_seq_wise_text) * 100)

pred_seq_wise_cluster = accuracyTopThreeKSCClsuter(test_with_cluster)
print('Accuracy with top 3 KSC when matching with cluster is',sum(pred_seq_wise_cluster)/len(pred_seq_wise_cluster) * 100)

np.amax(KSC_sim_array,axis =0 )
np.argmax(KSC_sim_array,axis =0 )
KSC_sim_array[4,65]
print(total_KSC_list[4])
print(total_KSC_list[65])

"""### We are getting arounud 75 accuracy when comparing to the top 3 KSC cluster """